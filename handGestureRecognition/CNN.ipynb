{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp38-cp38-win_amd64.whl (985 kB)\n",
      "Requirement already satisfied: torch==1.10.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.10.1)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.20.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==1.10.1->torchvision) (3.7.4.3)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.11.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VskMijOr0wOe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-BohvQ4k1BE"
   },
   "source": [
    "## CIFAR-10 MLP & CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UOEM8HG9200q"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lxgCYme9hz_D"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "h4XNzmNfu_3L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
    "                                  train = True,\n",
    "                                  download = True,\n",
    "                                  transform = transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
    "                                train = False,\n",
    "                                transform = transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                            batch_size = BATCH_SIZE,\n",
    "                                            shuffle = True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fmEw9Vk5mdv6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 3, 32, 32]) type: torch.FloatTensor\n",
      "y_train: torch.Size([32]) type: torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
    "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0u13o66meWm"
   },
   "outputs": [],
   "source": [
    "pltsize = 1\n",
    "plt.figure(figsize=(10 * pltsize, pltsize))\n",
    "\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
    "    plt.title('Class: ' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnW_8-u1iF94"
   },
   "source": [
    "### CIFAR - MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bCjW11cUncIX"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32 * 32 * 3)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim = 1)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "S3RkCQRXoYGl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (fc1): Linear(in_features=3072, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLP().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PlWzNa1Rodve"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "aCH8SooSlLjS"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pUvM68hHolNf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tTrain Loss: 2.307453\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tTrain Loss: 1.972034\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tTrain Loss: 1.879663\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tTrain Loss: 1.907304\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tTrain Loss: 1.792378\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tTrain Loss: 1.840407\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tTrain Loss: 1.684566\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tTrain Loss: 1.471382\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.0542, \tTest Accuracy: 36.92 % \n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tTrain Loss: 1.588428\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tTrain Loss: 1.694932\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tTrain Loss: 1.841916\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tTrain Loss: 1.516227\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tTrain Loss: 1.533644\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tTrain Loss: 1.631208\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tTrain Loss: 1.821410\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tTrain Loss: 1.402371\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0515, \tTest Accuracy: 40.88 % \n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tTrain Loss: 1.805700\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tTrain Loss: 1.533864\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tTrain Loss: 1.502182\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tTrain Loss: 1.466829\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tTrain Loss: 1.377963\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tTrain Loss: 1.655809\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tTrain Loss: 1.453573\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tTrain Loss: 1.389747\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0482, \tTest Accuracy: 45.63 % \n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tTrain Loss: 1.779324\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tTrain Loss: 1.424123\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tTrain Loss: 1.235601\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tTrain Loss: 1.544066\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tTrain Loss: 1.466585\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tTrain Loss: 1.799665\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tTrain Loss: 1.396687\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tTrain Loss: 1.320221\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0474, \tTest Accuracy: 45.53 % \n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tTrain Loss: 1.554802\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tTrain Loss: 1.773409\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tTrain Loss: 1.396394\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tTrain Loss: 1.516706\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tTrain Loss: 1.801408\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tTrain Loss: 1.338878\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tTrain Loss: 1.357525\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tTrain Loss: 1.671683\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.0462, \tTest Accuracy: 47.34 % \n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tTrain Loss: 1.471872\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tTrain Loss: 1.530201\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tTrain Loss: 1.612749\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tTrain Loss: 1.319229\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tTrain Loss: 1.308682\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tTrain Loss: 1.530947\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tTrain Loss: 1.097069\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tTrain Loss: 1.552914\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.0470, \tTest Accuracy: 46.62 % \n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tTrain Loss: 1.350764\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tTrain Loss: 1.438097\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tTrain Loss: 1.635431\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tTrain Loss: 1.315432\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tTrain Loss: 1.148008\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tTrain Loss: 1.208098\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tTrain Loss: 1.508304\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tTrain Loss: 1.516524\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.0468, \tTest Accuracy: 46.40 % \n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tTrain Loss: 1.595249\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tTrain Loss: 1.428240\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tTrain Loss: 1.391804\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tTrain Loss: 1.464894\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tTrain Loss: 1.429901\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tTrain Loss: 1.358111\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tTrain Loss: 1.681685\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tTrain Loss: 1.301564\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.0474, \tTest Accuracy: 46.37 % \n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tTrain Loss: 1.262449\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tTrain Loss: 1.344779\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tTrain Loss: 1.335085\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tTrain Loss: 1.330620\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tTrain Loss: 1.319349\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tTrain Loss: 1.250460\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tTrain Loss: 1.574803\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tTrain Loss: 1.690674\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.0457, \tTest Accuracy: 48.69 % \n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tTrain Loss: 1.494653\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tTrain Loss: 1.301415\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tTrain Loss: 1.526359\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tTrain Loss: 1.354373\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tTrain Loss: 1.594743\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tTrain Loss: 1.403426\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tTrain Loss: 1.623676\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tTrain Loss: 1.647010\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0450, \tTest Accuracy: 48.56 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tr1Q8amEmrnv"
   },
   "source": [
    "### CIFAR - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zHOMYlxv_oO"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # conv1 = input 3, output 8 channels, kernel 3, padding 1\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding = 1)\n",
    "        # conv2 = input 8, output 16 channels, kernet 3, padding 1\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size=3, padding=1)\n",
    "        # pool = kernel 2, stride 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        # fc layer 3 = input, 64, 32, 10\n",
    "        self.fc1 = nn.Linear(8 * 8 * 16, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 8 * 8 * 16)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLNAIgaTP4vJ"
   },
   "outputs": [],
   "source": [
    "model = CNN().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHX_T8JpP7pR"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35_e-3LwQVcn"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HezHz8TMQo6l"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvV3n7skoIv0"
   },
   "source": [
    "### CIFAR - ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvnDTVp6olvE"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride = 1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),\n",
    "                nn.BatchNorm2d(planes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(16, 2, stride = 1)\n",
    "        self.layer2 = self._make_layer(32, 2, stride = 2)\n",
    "        self.layer3 = self._make_layer(64, 2, stride = 2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks  - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(BasicBlock(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3t9neuZomnv"
   },
   "outputs": [],
   "source": [
    "model = ResNet().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adQinG1hopV8"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00kS545Jor82"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZeCacvEotmt"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Week 11_CNN.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
