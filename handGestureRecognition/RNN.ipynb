{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.10.1-cp38-cp38-win_amd64.whl (226.6 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mportlib-metadata (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.10.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5A1Rots52MU5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoHV_pc0AusC"
   },
   "source": [
    "## RNN with a simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8IrSaqim2RCM"
   },
   "outputs": [],
   "source": [
    "HIDDEN_DIM = 35\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "t8BT2CWM2cU7"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OSTLlt5k2sOh"
   },
   "outputs": [],
   "source": [
    "string = \"hello pytorch and data analytics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Tk1PgbXb3fr8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = \"abcdefghijklmnopqrstuvwxyz .01\"\n",
    "char_list = [i for i in chars]\n",
    "n_letters = len(char_list)\n",
    "n_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BsxIdHCG3kCt"
   },
   "outputs": [],
   "source": [
    "def string_to_onehot(string):\n",
    "    start = np.zeros(shape = n_letters, dtype = int)\n",
    "    end = np.zeros(shape = n_letters, dtype = int)\n",
    "\n",
    "    start[-2] = 1\n",
    "    end[-1] = 1\n",
    "\n",
    "    for i in string:\n",
    "        idx = char_list.index(i)\n",
    "        zero = np.zeros(shape = n_letters, dtype = int)\n",
    "        zero[idx] = 1\n",
    "        start = np.vstack([start, zero])\n",
    "    output = np.vstack([start, end])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RT4kKYRi4Ocg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_onehot(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gPIUsEBV2MQ3"
   },
   "outputs": [],
   "source": [
    "def onehot_to_string(onehot):\n",
    "    onehot_value = torch.Tensor.numpy(onehot)\n",
    "    return char_list[onehot_value.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_sj0QMsH2MIu"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.input2hidden = nn.Linear(input_size, hidden_size)\n",
    "        self.hidden2hidden = nn.Linear(hidden_size, hidden_size)\n",
    "        self.hidden2output = nn.Linear(hidden_size, output_size)\n",
    "        self.act_fn = nn.Tanh()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.act_fn(self.input2hidden(input) + self.hidden2hidden(hidden))\n",
    "        output = self.hidden2output(hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hoDJ1uvE7G4P"
   },
   "outputs": [],
   "source": [
    "rnn = RNN(n_letters, HIDDEN_DIM, n_letters).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "23--JfwD7axN"
   },
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss().to(device)\n",
    "optimizer_rnn = torch.optim.Adam(rnn.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "QYbiDE7e7zgV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of RNN(\n",
       "  (input2hidden): Linear(in_features=30, out_features=35, bias=True)\n",
       "  (hidden2hidden): Linear(in_features=35, out_features=35, bias=True)\n",
       "  (hidden2output): Linear(in_features=35, out_features=30, bias=True)\n",
       "  (act_fn): Tanh()\n",
       ")>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "W4dFUSgp8I54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7144, grad_fn=<AddBackward0>)\n",
      "tensor(0.0566, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    optimizer_rnn.zero_grad()\n",
    "    hidden = rnn.init_hidden()\n",
    "    total_loss = 0\n",
    "\n",
    "    for j in range(one_hot.size()[0]-1):\n",
    "        input_ = one_hot[j:j+1, :].to(device)\n",
    "        target = one_hot[j+1].to(device)\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        loss = loss_func(output.view(-1), target.view(-1))\n",
    "        total_loss += loss\n",
    "\n",
    "    total_loss.backward()\n",
    "    optimizer_rnn.step()\n",
    "\n",
    "    if i % 50 == 0:\n",
    "        print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "luZcsFpB9EA7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello pytorch andlytics.1tnd atan\n"
     ]
    }
   ],
   "source": [
    "start_tkn = torch.zeros(1, n_letters)\n",
    "start_tkn[:, -2] = 1\n",
    "\n",
    "with torch.no_grad():\n",
    "    hidden = rnn.init_hidden()\n",
    "    input_ = start_tkn.to(device)\n",
    "    output_string = \"\"\n",
    "\n",
    "    for i in range(len(string)):\n",
    "        output, hidden = rnn.forward(input_, hidden)\n",
    "        output_string += onehot_to_string(output.data)\n",
    "        input_ = output\n",
    "\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bo4bJdC7Azdi"
   },
   "source": [
    "## RNN and LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHO2B1thAPOA"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUTIUDW9Ezyx"
   },
   "outputs": [],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2Y4EMWTEnCo"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "import random\n",
    "import string\n",
    "import time, math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o10hD8eAE4s0"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "HIDDEN_DIM = 100\n",
    "BATCH_SIZE = 1\n",
    "CHUNK_LEN = 250\n",
    "NUM_LAYERS = 1\n",
    "EMBEDDING = 70\n",
    "LEARNING_RATE = 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UFfZrVIFJ0d"
   },
   "outputs": [],
   "source": [
    "characters = string.printable\n",
    "n_characters = len(characters)\n",
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_YtRGWZFaMw"
   },
   "outputs": [],
   "source": [
    "text_file = unidecode.unidecode(open('./data/input.txt').read())\n",
    "len_text_file = len(text_file)\n",
    "len_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gyzuBNT9Fqhu"
   },
   "outputs": [],
   "source": [
    "def random_chunk():\n",
    "    start_index = random.randint(0, len_text_file - CHUNK_LEN)\n",
    "    end_index = start_index + CHUNK_LEN + 1\n",
    "    return text_file[start_index : end_index]\n",
    "\n",
    "print(random_chunk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pc_drwFuFJwh"
   },
   "outputs": [],
   "source": [
    "def character_to_tensor(string):\n",
    "    tensor = torch.zeros(len(string)).long()\n",
    "    for char in range(len(string)):\n",
    "        tensor[char] = characters.index(string[char])\n",
    "    return tensor\n",
    "\n",
    "print(character_to_tensor('ABCde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OeHNVC2J-6U"
   },
   "outputs": [],
   "source": [
    "def random_training_set():\n",
    "    chunk = random_chunk()\n",
    "    input = character_to_tensor(chunk[:-1])\n",
    "    target = character_to_tensor(chunk[1:])\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GA7jZK6fKMwZ"
   },
   "outputs": [],
   "source": [
    "random_training_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPhplF0Ru6a9"
   },
   "source": [
    "### Make RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gh3P9qxiGnOk"
   },
   "outputs": [],
   "source": [
    "class EN_RNN_DE(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
    "        super(EN_RNN_DE, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.rnn = nn.RNN(self.embedding_size, self.hidden_size, self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        en_output = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.rnn(en_output, hidden)\n",
    "        de_output = self.decoder(output.view(1, -1))\n",
    "        return de_output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-P52tmBGnKa"
   },
   "outputs": [],
   "source": [
    "model = EN_RNN_DE(n_characters, EMBEDDING, HIDDEN_DIM, n_characters, NUM_LAYERS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvU9Ix01MtXu"
   },
   "outputs": [],
   "source": [
    "inp = character_to_tensor(\"A\")\n",
    "print(inp.size())\n",
    "hidden = model.init_hidden()\n",
    "print(hidden.size())\n",
    "out,hidden = model(inp,hidden)\n",
    "print(hidden.size())\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPc_WL61Bvl2"
   },
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YEMgXm97Gm4K"
   },
   "outputs": [],
   "source": [
    "optimizer_model = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MsSNaVDNJnUA"
   },
   "outputs": [],
   "source": [
    "for i in range(EPOCHS):\n",
    "    input, target = random_training_set()\n",
    "    input = input.to(device)\n",
    "    target = target.to(device)\n",
    "    hidden = model.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer_model.zero_grad()\n",
    "\n",
    "    for j in range(CHUNK_LEN-1):\n",
    "        x = input[j]\n",
    "        y_ = target[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y, hidden = model(x, hidden)\n",
    "        loss += loss_func(y, y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_model.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss/CHUNK_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_lp1RvesKro"
   },
   "outputs": [],
   "source": [
    "start_string = \"b\"\n",
    "\n",
    "input = character_to_tensor(start_string)\n",
    "hidden = model.init_hidden()\n",
    "\n",
    "print(start_string, end=\"\")\n",
    "\n",
    "for i in range(300):\n",
    "    output, hidden = model(input, hidden)\n",
    "\n",
    "    output_dist = output.data.view(-1).div(0.8).exp()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "    predicted_char = characters[top_i]\n",
    "\n",
    "    print(predicted_char, end=\"\")\n",
    "\n",
    "    input = character_to_tensor(predicted_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9UZMUNIu_Zh"
   },
   "source": [
    "### Make LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYu5wa03vBRu"
   },
   "outputs": [],
   "source": [
    "class EN_LSTM_DE(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers):\n",
    "        super(EN_LSTM_DE, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers)\n",
    "        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        en_output = self.encoder(input.view(1, -1))\n",
    "        output, (hidden, cell) = self.lstm(en_output, (hidden, cell))\n",
    "        de_output = self.decoder(output.view(1, -1))\n",
    "        return de_output, hidden, cell\n",
    "\n",
    "    def init_hidden(self):\n",
    "        hidden = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
    "        cell = torch.zeros(self.num_layers, BATCH_SIZE, self.hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYPo-9HLvvJF"
   },
   "outputs": [],
   "source": [
    "model_LSTM = EN_LSTM_DE(n_characters, EMBEDDING, HIDDEN_DIM, n_characters, NUM_LAYERS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BG9Kb0auyMfh"
   },
   "outputs": [],
   "source": [
    "model_LSTM.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7LJ0vVGsKlV"
   },
   "outputs": [],
   "source": [
    "input = character_to_tensor(\"A\")\n",
    "print(input)\n",
    "\n",
    "hidden, cell = model_LSTM.init_hidden()\n",
    "print(hidden.size())\n",
    "\n",
    "output, hidden, cell = model_LSTM(input, hidden, cell)\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1soDd8qbvtNU"
   },
   "outputs": [],
   "source": [
    "optimizer_lstm = torch.optim.Adam(model_LSTM.parameters(), lr = LEARNING_RATE)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmsoQgKByvJD"
   },
   "outputs": [],
   "source": [
    "for i in range(EPOCHS):\n",
    "    input, target = random_training_set()\n",
    "    input = input.to(device)\n",
    "    target = target.to(device)\n",
    "    hidden, cell = model_LSTM.init_hidden()\n",
    "\n",
    "    loss = torch.tensor([0]).type(torch.FloatTensor)\n",
    "    optimizer_lstm.zero_grad()\n",
    "\n",
    "    for j in range(CHUNK_LEN-1):\n",
    "        x = input[j]\n",
    "        y_ = target[j].unsqueeze(0).type(torch.LongTensor)\n",
    "        y, hidden, cell = model_LSTM(x, hidden, cell)\n",
    "        loss += loss_func(y, y_)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer_lstm.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss/CHUNK_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvJjMxcZvgSU"
   },
   "outputs": [],
   "source": [
    "start_string = \"b\"\n",
    "\n",
    "input = character_to_tensor(start_string)\n",
    "hidden, cell = model_LSTM.init_hidden()\n",
    "\n",
    "print(start_string, end=\"\")\n",
    "\n",
    "for i in range(300):\n",
    "    output, hidden, cell = model_LSTM(input, hidden, cell)\n",
    "\n",
    "    output_dist = output.data.view(-1).div(0.8).exp()\n",
    "    top_i = torch.multinomial(output_dist, 1)[0]\n",
    "    predicted_char = characters[top_i]\n",
    "\n",
    "    print(predicted_char, end=\"\")\n",
    "\n",
    "    input = character_to_tensor(predicted_char)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Week 12.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
